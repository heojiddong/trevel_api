import streamlit as st
import requests
import re

st.title("ğŸœ ì—¬í–‰ì§€ ë§›ì§‘ ì¶”ì²œ")

# ğŸ”‘ API í‚¤ ì§ì ‘ ì…ë ¥ (ë³´ì•ˆì— ìœ ì˜í•˜ì„¸ìš”)
KAKAO_API_KEY = "cf0f3e08c8579cf39f37df048fc9802a"
NAVER_CLIENT_ID = "288mB5F53usWEHGy9ip8"
NAVER_CLIENT_SECRET = "qV0iKKCgIG"

# ì—¬í–‰ì§€ í™•ì¸
location = st.session_state.get("location")
if not location:
    st.warning("â— ë¨¼ì € ë©”ì¸ í™”ë©´ì—ì„œ ì—¬í–‰ì§€ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    st.info("ğŸ“ ë©”ì¸ í˜ì´ì§€ì—ì„œ 'ë¶€ì‚°', 'ì œì£¼ë„' ë“± ì—¬í–‰ì§€ë¥¼ ì…ë ¥í•œ ë’¤ ì´ í˜ì´ì§€ë¥¼ ë‹¤ì‹œ ì—´ì–´ë³´ì„¸ìš”.")
    st.stop()

# Kakao API í•¨ìˆ˜ (size=10)
def search_places(query):
    headers = {
        "Authorization": f"KakaoAK {KAKAO_API_KEY}"
    }
    params = {"query": query, "size": 10}
    res = requests.get("https://dapi.kakao.com/v2/local/search/keyword.json", headers=headers, params=params)
    return res.json().get("documents", [])

# íŠ¹ì§• í‚¤ì›Œë“œ â†’ ìì—°ì–´ ë¬¸ì¥ ë§¤í•‘
feature_descriptions = {
    "ê°€ì„±ë¹„": "ê°€ì„±ë¹„ê°€ ì¢‹ë‹¤ëŠ” í‰ì´ ë§ìŠµë‹ˆë‹¤.",
    "ë·°": "ì „ë§ì´ ì¢‹ì€ ê³³ìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤.",
    "ì¹œì ˆ": "ì§ì›ë“¤ì´ ì¹œì ˆí•˜ë‹¤ëŠ” í›„ê¸°ê°€ ìˆìŠµë‹ˆë‹¤.",
    "ì¸í…Œë¦¬ì–´": "ì¸í…Œë¦¬ì–´ê°€ ì„¸ë ¨ë˜ì—ˆë‹¤ëŠ” í‰ì´ ë§ìŠµë‹ˆë‹¤.",
    "í˜¼ë°¥": "í˜¼ë°¥í•˜ê¸° í¸ì•ˆí•œ ë¶„ìœ„ê¸°ì…ë‹ˆë‹¤.",
    "ë°ì´íŠ¸": "ë°ì´íŠ¸ ì¥ì†Œë¡œë„ ì˜ ì–´ìš¸ë¦°ë‹¤ëŠ” í‰ì´ ìˆìŠµë‹ˆë‹¤.",
    "ì¤„": "ì¤„ì„ ì„œì•¼ í•  ìˆ˜ë„ ìˆìœ¼ë‹ˆ ì°¸ê³ í•˜ì„¸ìš”.",
    "ëŒ€ê¸°": "ëŒ€ê¸° ì‹œê°„ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    "ì˜ˆì•½": "ì˜ˆì•½ì´ í•„ìš”í•œ ì‹ë‹¹ì…ë‹ˆë‹¤.",
    "ê¹”ë”": "ê¹”ë”í•˜ê³  ì •ëˆëœ í™˜ê²½ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.",
    "ì¡°ìš©": "ì¡°ìš©í•˜ê³  ì•„ëŠ‘í•œ ë¶„ìœ„ê¸°ì…ë‹ˆë‹¤.",
    "ê°ì„±": "ê°ì„±ì ì¸ ë¶„ìœ„ê¸°ë¡œ ê¾¸ë©°ì ¸ ìˆìŠµë‹ˆë‹¤.",
    "í‘¸ì§": "ì–‘ì´ í‘¸ì§í•˜ë‹¤ëŠ” í›„ê¸°ê°€ ë§ìŠµë‹ˆë‹¤.",
    "ë¶„ìœ„ê¸°": "ë¶„ìœ„ê¸°ê°€ ì¢‹ë‹¤ëŠ” í‰ì´ ìˆìŠµë‹ˆë‹¤.",
    "ì›¨ì´íŒ…": "ì›¨ì´íŒ…ì´ ê¸¸ ìˆ˜ ìˆìœ¼ë‹ˆ ì°¸ê³ í•˜ì„¸ìš”.",
    "ì„œë¹„ìŠ¤": "ì„œë¹„ìŠ¤ê°€ ì¢‹ë‹¤ëŠ” í‰ê°€ê°€ ìˆìŠµë‹ˆë‹¤.",
    "ì²­ê²°": "ë§¤ì¥ì´ ì²­ê²°í•˜ê²Œ ìœ ì§€ë˜ê³  ìˆìŠµë‹ˆë‹¤."
}

# ë¸”ë¡œê·¸ ê²€ìƒ‰ ë° í‚¤ì›Œë“œ/ë§í¬ ì¶”ì¶œ
def get_food_and_features(query, place_name):
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    params = {
        "query": query,
        "display": 5,
        "sort": "sim"
    }
    res = requests.get("https://openapi.naver.com/v1/search/blog.json", headers=headers, params=params)
    items = res.json().get("items", [])
    if not items:
        return None, None, []

    combined_text = ""
    links = []
    for item in items:
        title = re.sub(r"<.*?>", "", item.get("title", ""))
        desc = re.sub(r"<.*?>", "", item.get("description", ""))
        link = item.get("link", "")

        if place_name not in title and place_name not in desc:
            continue

        combined_text += f"{title} {desc} "
        links.append((title.strip(), link))
        if len(links) >= 3:
            break

    if not links:
        return None, None, []

    food_keywords = [
        "ëˆê°€ìŠ¤", "ì´ˆë°¥", "ë¼ë©´", "íšŒ", "êµ­ë°¥", "ë–¡ë³¶ì´", "ë§ˆë¼íƒ•", "ìŠ¤ì‹œ", "ìš°ë™", "ì¡±ë°œ",
        "ëƒ‰ë©´", "í•´ì‚°ë¬¼", "íŒŒìŠ¤íƒ€", "ìŠ¤í…Œì´í¬", "í•œì‹", "ì–‘ì‹", "ì¤‘ì‹", "ë¶„ì‹", "ë·”í˜", "ì •ì‹"
    ]
    feature_keywords = list(feature_descriptions.keys()) + ["ë§›ì§‘"]

    found_foods = sorted(set([k for k in food_keywords if k in combined_text]))
    found_features = sorted(set([k for k in feature_keywords if k in combined_text]))

    return found_foods, found_features, links

# ì¥ì†Œ ê²€ìƒ‰
query =
