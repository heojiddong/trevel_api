import streamlit as st
import requests
import re

st.title("ğŸœ ì—¬í–‰ì§€ ë§›ì§‘ ì¶”ì²œ")

# ì—¬í–‰ì§€ í™•ì¸
location = st.session_state.get("location")
if not location:
    st.warning("â— ë¨¼ì € ë©”ì¸ í™”ë©´ì—ì„œ ì—¬í–‰ì§€ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    st.info("ğŸ“ ë©”ì¸ í˜ì´ì§€ì—ì„œ 'ë¶€ì‚°', 'ì œì£¼ë„' ë“± ì—¬í–‰ì§€ë¥¼ ì…ë ¥í•œ ë’¤ ì´ í˜ì´ì§€ë¥¼ ë‹¤ì‹œ ì—´ì–´ë³´ì„¸ìš”.")
    st.stop()

# Kakao API í•¨ìˆ˜ (size=45ë¡œ ìµœëŒ€ ê²°ê³¼ ìš”ì²­)
def search_places(query):
    headers = {
        "Authorization": f"KakaoAK {st.secrets['KAKAO_API_KEY']}"
    }
    params = {"query": query, "size": 45}
    res = requests.get("https://dapi.kakao.com/v2/local/search/keyword.json", headers=headers, params=params)
    return res.json().get("documents", [])

# íŠ¹ì§• í‚¤ì›Œë“œ â†’ ìì—°ì–´ ë¬¸ì¥ ë§¤í•‘ (â€» 'ë§›ì§‘' ì œì™¸)
feature_descriptions = {
    "ê°€ì„±ë¹„": "ê°€ì„±ë¹„ê°€ ì¢‹ë‹¤ëŠ” í‰ì´ ë§ìŠµë‹ˆë‹¤.",
    "ë·°": "ì „ë§ì´ ì¢‹ì€ ê³³ìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤.",
    "ì¹œì ˆ": "ì§ì›ë“¤ì´ ì¹œì ˆí•˜ë‹¤ëŠ” í›„ê¸°ê°€ ìˆìŠµë‹ˆë‹¤.",
    "ì¸í…Œë¦¬ì–´": "ì¸í…Œë¦¬ì–´ê°€ ì„¸ë ¨ë˜ì—ˆë‹¤ëŠ” í‰ì´ ë§ìŠµë‹ˆë‹¤.",
    "í˜¼ë°¥": "í˜¼ë°¥í•˜ê¸° í¸ì•ˆí•œ ë¶„ìœ„ê¸°ì…ë‹ˆë‹¤.",
    "ë°ì´íŠ¸": "ë°ì´íŠ¸ ì¥ì†Œë¡œë„ ì˜ ì–´ìš¸ë¦°ë‹¤ëŠ” í‰ì´ ìˆìŠµë‹ˆë‹¤.",
    "ì¤„": "ì¤„ì„ ì„œì•¼ í•  ìˆ˜ë„ ìˆìœ¼ë‹ˆ ì°¸ê³ í•˜ì„¸ìš”.",
    "ëŒ€ê¸°": "ëŒ€ê¸° ì‹œê°„ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    "ì˜ˆì•½": "ì˜ˆì•½ì´ í•„ìš”í•œ ì‹ë‹¹ì…ë‹ˆë‹¤.",
    "ê¹”ë”": "ê¹”ë”í•˜ê³  ì •ëˆëœ í™˜ê²½ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.",
    "ì¡°ìš©": "ì¡°ìš©í•˜ê³  ì•„ëŠ‘í•œ ë¶„ìœ„ê¸°ì…ë‹ˆë‹¤.",
    "ê°ì„±": "ê°ì„±ì ì¸ ë¶„ìœ„ê¸°ë¡œ ê¾¸ë©°ì ¸ ìˆìŠµë‹ˆë‹¤.",
    "í‘¸ì§": "ì–‘ì´ í‘¸ì§í•˜ë‹¤ëŠ” í›„ê¸°ê°€ ë§ìŠµë‹ˆë‹¤.",
    "ë¶„ìœ„ê¸°": "ë¶„ìœ„ê¸°ê°€ ì¢‹ë‹¤ëŠ” í‰ì´ ìˆìŠµë‹ˆë‹¤.",
    "ì›¨ì´íŒ…": "ì›¨ì´íŒ…ì´ ê¸¸ ìˆ˜ ìˆìœ¼ë‹ˆ ì°¸ê³ í•˜ì„¸ìš”.",
    "ì„œë¹„ìŠ¤": "ì„œë¹„ìŠ¤ê°€ ì¢‹ë‹¤ëŠ” í‰ê°€ê°€ ìˆìŠµë‹ˆë‹¤.",
    "ì²­ê²°": "ë§¤ì¥ì´ ì²­ê²°í•˜ê²Œ ìœ ì§€ë˜ê³  ìˆìŠµë‹ˆë‹¤."
}

# ë¸”ë¡œê·¸ ê²€ìƒ‰ ë° í‚¤ì›Œë“œ/ë§í¬ ì¶”ì¶œ
def get_food_and_features(query):
    headers = {
        "X-Naver-Client-Id": st.secrets["NAVER_CLIENT_ID"],
        "X-Naver-Client-Secret": st.secrets["NAVER_CLIENT_SECRET"]
    }
    params = {
        "query": query,
        "display": 3,
        "sort": "sim"
    }
    res = requests.get("https://openapi.naver.com/v1/search/blog.json", headers=headers, params=params)
    items = res.json().get("items", [])
    if not items:
        return None, None, []

    combined_text = ""
    links = []
    for item in items:
        title = re.sub(r"<.*?>", "", item.get("title", ""))
        desc = re.sub(r"<.*?>", "", item.get("description", ""))
        link = item.get("link", "")
        combined_text += f"{title} {desc} "
        links.append((title, link))

    food_keywords = [
        "ëˆê°€ìŠ¤", "ì´ˆë°¥", "ë¼ë©´", "íšŒ", "êµ­ë°¥", "ë–¡ë³¶ì´", "ë§ˆë¼íƒ•", "ìŠ¤ì‹œ", "ìš°ë™", "ì¡±ë°œ",
        "ëƒ‰ë©´", "í•´ì‚°ë¬¼", "íŒŒìŠ¤íƒ€", "ìŠ¤í…Œì´í¬", "í•œì‹", "ì–‘ì‹", "ì¤‘ì‹", "ë¶„ì‹", "ë·”í˜", "ì •ì‹"
    ]
    feature_keywords = list(feature_descriptions.keys()) + ["ë§›ì§‘"]

    found_foods = sorted(set([k for k in food_keywords if k in combined_text]))
    found_features = sorted(set([k for k in feature_keywords if k in combined_text]))

    return found_foods, found_features, links

# Kakao ì¥ì†Œ ê²€ìƒ‰
query = f"{location} ë§›ì§‘"
all_results = search_places(query)

# í›„ê¸° í‚¤ì›Œë“œ ì¡°ê±´ ì™„í™”: ìŒì‹ or íŠ¹ì§•ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì¶”ì²œ
filtered_results = []
for place in all_results:
    name = place["place_name"]
    food, features, links = get_food_and_features(f"{location} {name}")
    if (food or features) and links:
        clean_features = [f for f in features if f != "ë§›ì§‘"]
        filtered_results.append((place, food, clean_features, links))

# ê²°ê³¼ ì¶œë ¥
if filtered_results:
    for place, food, features, links in filtered_results:
        name = place["place_name"]
        address = place["road_address_name"] or place["address_name"]
        map_url = place["place_url"]

        st.markdown(f"### ğŸ“ {name}")
        st.write(f"ğŸ“Œ ì£¼ì†Œ: {address}")
        st.markdown(f"ğŸ”— [ì¹´ì¹´ì˜¤ë§µ ë³´ê¸°]({map_url})")
        if food:
            st.write("ğŸ½ï¸ ëŒ€í‘œ ìŒì‹:", ", ".join(food))
        if features:
            for f in features:
                if f in feature_descriptions:
                    st.write("ğŸ’¬", feature_descriptions[f])
        if links:
            st.write("ğŸ“° ê´€ë ¨ ë¸”ë¡œê·¸ í›„ê¸°:")
            for title, url in links:
                clean_title = re.sub(r"[^\w\sê°€-í£]", "", title).strip() or "ë¸”ë¡œê·¸ ê¸€ ë³´ê¸°"
                st.markdown(f"- [{clean_title}]({url})")
        st.markdown("---")
else:
    st.info("ì¶”ì²œí•  ë§Œí•œ ë§›ì§‘ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—¬í–‰ì§€ë¥¼ ë°”ê¿”ë³´ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”.")
